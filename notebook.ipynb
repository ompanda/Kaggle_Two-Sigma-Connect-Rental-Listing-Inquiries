{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0,
  "cells": [
    {
      "cell_type": "markdown",
      "source": "Import necessary modules",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import log_loss\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"../input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df = pd.read_json(open(\"../input/train.json\", \"r\"))\ndf.head(5)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df.shape",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "numeric_features = [\"bathrooms\", \"bedrooms\", \"latitude\", \"longitude\", \"price\"]\nX = df[numeric_features]\ny = df[\"interest_level\"]\nX.head()",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.33)\n\nrandom_forest_classifier = RandomForestClassifier(n_estimators=1500)\nrandom_forest_classifier.fit(X_train, y_train)\ny_val_pred = random_forest_classifier.predict_proba(X_val)\nlog_loss(y_val, y_val_pred)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": "Prediction",
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "df_test = pd.read_json(open(\"../input/test.json\", \"r\"))\nX_test = df_test[numeric_features]\n\ny_test = random_forest_classifier.predict_proba(X_test)",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": "interest_level = {label: i for i, label in enumerate(random_forest_classifier.classes_)}\n\nouput_submission = pd.DataFrame()\nouput_submission[\"listing_id\"] = df_test[\"listing_id\"]\nfor label in [\"high\", \"medium\", \"low\"]:\n    ouput_submission[label] = y_test[:, interest_level[label]]\nouput_submission.to_csv(\"submission.csv\", index=False)\n",
      "execution_count": null,
      "outputs": [],
      "metadata": {}
    }
  ]
}